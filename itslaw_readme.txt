====================================================================================================

这个爬虫是为了爬取 https://www.itslaw.com/ 网站上的案例内容

====================================================================================================

运行爬虫

====================


1. 登录服务器, 进入 fst 用户下的 /marti/server_itslaw 目录


2. 开启虚拟环境

输入 workon itslaw 
(这个环境配置好了当前爬虫所需要的模块, 为 python3 版本)


3. 运行爬虫

输入 scrapy crawl simpleitslaw
(另一个名为 itslaw 的爬虫写的比较早, 现在不用)
(运行爬虫之后会提示输入一个起始url, 比如
https://www.itslaw.com/detail?judgementId=eda7ebe3-2e20-49e9-98ca-b2a5017b5052&area=1&index=1&sortType=1&count=1955618&conditions=region%2B9%2B1%2B上海市 )
(起始 url 需要手动维护 并需要规划好一次爬取的范围与数量 建议一次爬取的数量限制在 10,000以内比较好)
(爬取原理是通过当前页面的"下一篇"链接爬取下一个页面)


4. 运行完毕, 爬取的数据以 json 格式存放在 ../server_itslaw/scraped_files/ 目录下

(如果不是正常停止运行 则得到的 json 文件在最后会缺少一个结束中括号 可以手动添加一个 "]" 以便在浏览器中查看文件内容)


5. 如果是以上面这种方式运行, 断开 ssh 连接时爬虫也会中断, 可以使用 tmux 命令解决

type "tmux" to start a new session

do anything you want just like in a shell terminal

type "Ctrl + b" and then "d (detach)" to detach the session

--------------------------------------------------------------------------

type "tmux attach" to attach your session again 

--------------------------------------------------------------------------

type "Ctrl + b" and then "[" to scroll in tmux session



====================================================================================================

爬取文件的存放与传输

====================

爬虫文件存放在 node 46 与 node 50, 共两处备份

具体位置为 /home/fst/marti/files

文件格式为 每一个地级市的文件合成一个压缩包 目前已经爬取了宁夏省所有的地级市(估计40万案例) 包括

1. 宁夏银川市.zip
2. 宁夏石嘴山市.zip
...
5. 宁夏中卫市.zip

上传文件到服务器 scp -i ~/.ssh/fst_rsa 本地文件 fst@IPaddress:服务器目录
下载文件到本地 scp -i ~/.ssh/fst_rsa fst@IPaddress:服务器目录/文件 本地目录
如果需要递归传输目录中的内容需要加 -r



====================================================================================================

文件清单

====================

1. 文件 itslaw_requirements.txt  --  爬虫运行环境要求，可以由此文件直接生成相应的虚拟环境
2. 目录 itslaw  --  在本机实验的爬虫
3. 目录 server_itslaw --  部署到服务器上到爬虫（需要设置代理）
4. 目录 Mo  --  之前由莫浩然同学交接的工作内容（与以上内容不重复部分）




